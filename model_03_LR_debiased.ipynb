{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings( 'ignore' )\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import All_RUT_Models\n",
    "import RUT_Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters for this model\n",
    "\n",
    "penalty = 'l2'\n",
    "C = 18\n",
    "solver = 'newton-cg'\n",
    "class_weight='balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'LR_debiased'\n",
    "\n",
    "modelpath = './Models/' + modelname + '/'\n",
    "\n",
    "if not os.path.exists( modelpath ):\n",
    "    os.makedirs( modelpath )\n",
    "if not os.path.exists( './Results/' ):\n",
    "    os.makedirs( './Results/' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99157, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_sc(x):\n",
    "    alphanumeric = [character for character in x if (character.isalnum()) | (character==' ')]\n",
    "    alphanumeric = \"\".join(alphanumeric)\n",
    "    return alphanumeric\n",
    "\n",
    "df = pd.read_csv('wiki_debias_train.csv')\n",
    "# df = pd.read_csv(r'training_data/wiki_train.csv')\n",
    "df = df[['comment', 'is_toxic']]\n",
    "df.columns = ['Comment', 'Toxic']\n",
    "df.Comment = df.Comment.astype( 'str' )\n",
    "df.Comment = df.Comment.apply(lambda x: x.lower())\n",
    "df.Comment = df.Comment.apply(lambda x: remove_sc(x))\n",
    "df['Toxic'][df['Toxic'].astype(bool) == True] = 1\n",
    "df['Toxic'][df['Toxic'].astype(bool) == False] = 0\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runtime: 0:00:15.38\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings( 'ignore' )\n",
    "start_time = time.time()\n",
    "\n",
    "# valaccuracy, valprecision, valrecall, valf1, valcm = [], [], [], [], []\n",
    "# testaccuracy, testprecision, testrecall, testf1, testcm = [], [], [], [], []\n",
    "# com_text, com_label, com_predicted, com_prob = [], [], [], []\n",
    "# com_indices = []\n",
    "\n",
    "# fold = 1\n",
    "# for train_index, test_index in skf.split( df.Comment, df.Toxic ):\n",
    "# tf.idf vectorization    \n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split( df.Comment, df.Toxic, test_size = 0.20, random_state = 0)\n",
    "\n",
    "vectorizer = TfidfVectorizer(  )\n",
    "vectorizer.fit( X_train.values )\n",
    "\n",
    "xtrain = vectorizer.transform( X_train.values )\n",
    "xtest = vectorizer.transform( X_test.values )\n",
    "ytrain = y_train.values\n",
    "ytest = y_test.values\n",
    "\n",
    "# split train and val\n",
    "xtrain, xval, ytrain, yval = train_test_split( xtrain, ytrain, test_size=0.10, random_state=1 )\n",
    "\n",
    "# define a model\n",
    "model = All_RUT_Models.LR_Model( pen=penalty, c=C, sol=solver, class_weight=class_weight )\n",
    "\n",
    "# train the model\n",
    "model.fit( xtrain, ytrain )\n",
    "\n",
    "# save the model\n",
    "with open( modelpath + modelname + '.pkl', 'wb' ) as f:\n",
    "    pickle.dump( model, f )\n",
    "\n",
    "# load saved model\n",
    "with open( modelpath + modelname + '.pkl', 'rb' ) as f:\n",
    "    model = pickle.load( f )\n",
    "\n",
    "# get predictions (probabilities) for validation and test sets respectively\n",
    "valpredictions = model.predict_proba( xval )[ :, 1 ]\n",
    "testpredictions = model.predict_proba( xtest )[ :, 1 ]\n",
    "\n",
    "# optimizer threshold on validation set\n",
    "threshold = 0.5 #RUT_Utils.optimize_threshold( yval, valpredictions )\n",
    "\n",
    "# save accuracy, precision, recall, f1 and confusion matrices\n",
    "vallabels = (valpredictions>=threshold).astype( 'int32' )\n",
    "testlabels = (testpredictions>=threshold).astype( 'int32' )\n",
    "\n",
    "valaccuracy = accuracy_score( yval, vallabels )\n",
    "valprecision = precision_score( yval, vallabels )\n",
    "valrecall =  recall_score( yval, vallabels )\n",
    "valf1 =  f1_score( yval, vallabels )\n",
    "valcm =  confusion_matrix( yval, vallabels )    \n",
    "\n",
    "testaccuracy =  accuracy_score( ytest, testlabels )\n",
    "testprecision =  precision_score( ytest, testlabels )\n",
    "testrecall =  recall_score( ytest, testlabels )\n",
    "testf1 =  f1_score( ytest, testlabels )\n",
    "testcm =  confusion_matrix( ytest, testlabels )\n",
    "\n",
    "# save for future analysis and ensemble\n",
    "# com_indices.extend( test_index.tolist() )\n",
    "# com_text.extend( df.loc[ test_index ][ 'Comment' ] )\n",
    "# com_label.extend( df.loc[ test_index ][ 'Toxic' ].tolist() )\n",
    "# com_predicted.extend( testlabels )\n",
    "# com_prob.extend( testpredictions )\n",
    "\n",
    "# print( 'Fold: {:02d} out of {:02d} completed.'.format( fold, skf.get_n_splits() ) )\n",
    "\n",
    "# fold = fold + 1\n",
    "time_took = time.time() - start_time\n",
    "print(f\"Total runtime: {hms_string(time_took)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7990961809727809\n",
      "\n",
      "Test Precision: 0.9654093163157467\n",
      "\n",
      "Test Recall: 0.6204221305051982\n",
      "\n",
      "Test F1: 0.755390878442847\n",
      "[[23751 14531]\n",
      " [  851 37431]]\n",
      "\n",
      "\n",
      "TN :37431\n",
      "FP :851\n",
      "FN :14531\n",
      "TP :23751\n"
     ]
    }
   ],
   "source": [
    "synthetic = pd.read_csv('Synthetic_debias_test.csv')\n",
    "\n",
    "synthetic_comments = vectorizer.transform( synthetic['Comment'].values )\n",
    "\n",
    "synthetic_y = synthetic['Toxic'].values\n",
    "\n",
    "synthetic_predictions = model.predict_proba( synthetic_comments )[ :, 1 ]\n",
    "\n",
    "synthetic_labels = (synthetic_predictions>=threshold).astype( 'int32' )\n",
    "synthetic_accuracy =  accuracy_score( synthetic_y, synthetic_labels )\n",
    "synthetic_precision =  precision_score( synthetic_y, synthetic_labels )\n",
    "synthetic_recall =  recall_score( synthetic_y, synthetic_labels )\n",
    "synthetic_f1 =  f1_score( synthetic_y, synthetic_labels )\n",
    "synthetic_cm =  confusion_matrix( synthetic_y, synthetic_labels )\n",
    "\n",
    "print( 'Test Accuracy: ' +  str(synthetic_accuracy) + '\\n' )\n",
    "\n",
    "print( 'Test Precision: ' +  str(synthetic_precision) + '\\n' )\n",
    "\n",
    "print( 'Test Recall: ' +  str(synthetic_recall) + '\\n' )\n",
    "\n",
    "print( 'Test F1: ' + str(synthetic_f1) )\n",
    "\n",
    "print( np.rot90(np.rot90(synthetic_cm)) )\n",
    "\n",
    "_tn, _fp, _fn, _tp = synthetic_cm.ravel()\n",
    "print ( '\\n\\nTN :' +  str(_tn) )\n",
    "print ( 'FP :' +  str(_fp) )\n",
    "print ( 'FN :' +  str(_fn) )\n",
    "print ( 'TP :' +  str(_tp) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic.drop(columns='PredictedLabel', inplace=True)\n",
    "synthetic['Predicted_Probability'] = synthetic_predictions\n",
    "synthetic['Predicted_Label'] = synthetic_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Toxic</th>\n",
       "      <th>Jew</th>\n",
       "      <th>Muslim</th>\n",
       "      <th>Christian</th>\n",
       "      <th>Hindu</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Black</th>\n",
       "      <th>White</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>Heterosexual</th>\n",
       "      <th>Homosexual_gay_or_lesbian</th>\n",
       "      <th>Sum</th>\n",
       "      <th>Predicted_Probability</th>\n",
       "      <th>Predicted_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>murder american</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882743</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>respect trans</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>respect homosexual</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hug mexican</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kill sikh</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.985878</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Comment  Toxic  Jew  Muslim  Christian  Hindu  Asian  Black  \\\n",
       "0     murder american      1    0       0          0      0      0      0   \n",
       "1       respect trans      0    0       0          0      0      0      0   \n",
       "2  respect homosexual      0    0       0          0      0      0      0   \n",
       "3         hug mexican      0    0       0          0      0      0      0   \n",
       "4           kill sikh      1    0       0          0      0      0      0   \n",
       "\n",
       "   White  Female  Male  Heterosexual  Homosexual_gay_or_lesbian  Sum  \\\n",
       "0      0       0     0             0                          0    0   \n",
       "1      0       0     0             0                          0    0   \n",
       "2      0       0     0             0                          1    1   \n",
       "3      0       0     0             0                          0    0   \n",
       "4      0       0     0             0                          0    0   \n",
       "\n",
       "   Predicted_Probability  Predicted_Label  \n",
       "0               0.882743                1  \n",
       "1               0.002476                0  \n",
       "2               0.012130                0  \n",
       "3               0.101476                0  \n",
       "4               0.985878                1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic.to_csv('./Results/'+modelname+'_synthetic_predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
