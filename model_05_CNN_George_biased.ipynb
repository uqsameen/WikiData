{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings( 'ignore' )\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import All_RUT_Models\n",
    "import RUT_Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters for this model\n",
    "\n",
    "max_len = 150\n",
    "embed_size = 300\n",
    "pre_trained_flag = True\n",
    "embed_trainable = False\n",
    "emb_weights_init = 'glorot_normal'\n",
    "lr_rate = 0.001\n",
    "optimizer = 'adam'\n",
    "multi_gpu_flag = False\n",
    "gpus = 2\n",
    "batch = 64\n",
    "nepochs = 30\n",
    "patience = 7\n",
    "decay = True\n",
    "decay_rate = 0.5\n",
    "decay_after = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddingfile = './General_Embeddings/glove.txt'\n",
    "#embeddingfile = './General_Embeddings/w2v_cbow.txt'\n",
    "embeddingfile = './General_Embeddings/w2v_sg.txt'\n",
    "#embeddingfile = './General_Embeddings/ft_cbow.vec'\n",
    "# embeddingfile = './General_Embeddings/ft_sg.vec'\n",
    "\n",
    "embedding_matrix = []\n",
    "max_features = 149024\n",
    "\n",
    "modelname = 'CNN_George_w2v_sg_biased'\n",
    "\n",
    "modelpath = './Models/' + modelname + '/'\n",
    "\n",
    "if not os.path.exists( modelpath ):\n",
    "    os.makedirs( modelpath )\n",
    "if not os.path.exists( './Results/' ):\n",
    "    os.makedirs( './Results/' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95692, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_sc(x):\n",
    "    alphanumeric = [character for character in x if (character.isalnum()) | (character==' ')]\n",
    "    alphanumeric = \"\".join(alphanumeric)\n",
    "    return alphanumeric\n",
    "\n",
    "df = pd.read_csv('wiki_train.csv')\n",
    "# df = pd.read_csv(r'training_data/wiki_train.csv')\n",
    "df = df[['comment', 'is_toxic']]\n",
    "df.columns = ['Comment', 'Toxic']\n",
    "df.Comment = df.Comment.astype( 'str' )\n",
    "df.Comment = df.Comment.apply(lambda x: x.lower())\n",
    "df.Comment = df.Comment.apply(lambda x: remove_sc(x))\n",
    "df['Toxic'][df['Toxic'].astype(bool) == True] = 1\n",
    "df['Toxic'][df['Toxic'].astype(bool) == False] = 0\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs( word, *arr ):\n",
    "    return word, np.asarray( arr, dtype='float32' )\n",
    "\n",
    "def get_vectors( tokenizer ):\n",
    "    word_index = tokenizer.word_index\n",
    "    num_words = min( max_features, len( word_index ) + 1 )\n",
    "    embedding_matrix = np.zeros( ( num_words, embed_size ) )\n",
    "    for word, i in word_index.items(  ):\n",
    "        if i >= max_features:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get( word )\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    gc.collect()\n",
    "    return embedding_matrix\n",
    "\n",
    "if pre_trained_flag == True:\n",
    "    embeddings_index = dict( get_coefs( *o.rstrip().rsplit(' ') ) for o in open( embeddingfile, encoding='utf-8' ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000 --MaxValF1: 0.66242038 --CurValF1: 0.66242038 --Patience: 00 --improved f1: 0.66242038\n",
      "Epoch: 001 --MaxValF1: 0.66319703 --CurValF1: 0.66319703 --Patience: 00 --improved f1: 0.66319703\n",
      "Epoch: 002 --MaxValF1: 0.68861847 --CurValF1: 0.68861847 --Patience: 00 --improved f1: 0.68861847\n",
      "Epoch: 003 --MaxValF1: 0.68861847 --CurValF1: 0.67791636 --Patience: 00\n",
      "Epoch: 004 --MaxValF1: 0.68861847 --CurValF1: 0.67927076 --Patience: 01\n",
      "Epoch: 005 --MaxValF1: 0.68861847 --CurValF1: 0.68488990 --Patience: 02\n",
      "Epoch: 006 --MaxValF1: 0.68861847 --CurValF1: 0.67730239 --Patience: 03\n",
      "Epoch: 007 --MaxValF1: 0.68861847 --CurValF1: 0.66819222 --Patience: 04\n",
      "Epoch: 008 --MaxValF1: 0.68861847 --CurValF1: 0.67412379 --Patience: 05\n",
      "Epoch: 009 --MaxValF1: 0.68861847 --CurValF1: 0.67238690 --Patience: 06\n",
      "Training stopped due to the patience parameter. --Patience: 07\n",
      "Total runtime: 0:01:36.17\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings( 'ignore' )\n",
    "start_time = time.time()\n",
    "\n",
    "# valaccuracy, valprecision, valrecall, valf1, valcm = [], [], [], [], []\n",
    "# testaccuracy, testprecision, testrecall, testf1, testcm = [], [], [], [], []\n",
    "# com_text, com_label, com_predicted, com_prob = [], [], [], []\n",
    "# com_indices = []\n",
    "\n",
    "# fold = 1\n",
    "# for train_index, test_index in skf.split( df.Comment, df.Toxic ):\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split( df.Comment, df.Toxic, test_size = 0.20, random_state = 0)\n",
    "\n",
    "# clearing previous sessions\n",
    "K.clear_session()\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# tokenization with keras tokenizer\n",
    "tokenizer = text.Tokenizer( num_words=max_features )\n",
    "tokenizer.fit_on_texts( X_train.values )\n",
    "\n",
    "traincomments = tokenizer.texts_to_sequences( X_train.values )\n",
    "testcomments = tokenizer.texts_to_sequences( X_test.values )\n",
    "\n",
    "# pad the tokenized sequences\n",
    "xtrain = sequence.pad_sequences( traincomments, maxlen=max_len )\n",
    "xtest = sequence.pad_sequences( testcomments, maxlen=max_len )\n",
    "\n",
    "ytrain = y_train.values\n",
    "ytest = y_test.values\n",
    "\n",
    "# split train and val\n",
    "xtrain, xval, ytrain, yval = train_test_split( xtrain, ytrain, test_size=0.10, random_state=0 )\n",
    "\n",
    "ytrain = to_categorical( ytrain, 2 )\n",
    "yval = to_categorical( yval, 2 )\n",
    "ytest = to_categorical( ytest, 2 )\n",
    "\n",
    "# check if pre-trained word embeddings flag is true\n",
    "if pre_trained_flag == True:\n",
    "    embedding_matrix = get_vectors( tokenizer=tokenizer)\n",
    "\n",
    "# define a model\n",
    "model = All_RUT_Models.CNN_George( tokenizer=tokenizer, max_len=max_len, embed_size=embed_size,\n",
    "                                  embedding_matrix=embedding_matrix, embed_trainable=embed_trainable,\n",
    "                                  emb_weights_init=emb_weights_init, optimizer=optimizer,\n",
    "                                  multi_gpu_flag=multi_gpu_flag, gpus=gpus )\n",
    "\n",
    "K.set_value( model.optimizer.lr, lr_rate )\n",
    "\n",
    "# train the model with callbacks for early stopping\n",
    "f1metric = RUT_Utils.F1Metrics( modelpath + modelname + '.h5', patience=patience,\n",
    "                               decay=decay, decay_rate=decay_rate, decay_after=decay_after, softmax=True )\n",
    "hist = model.fit( xtrain, ytrain, batch_size=batch, validation_data=( xval,yval ),\n",
    "                 epochs=nepochs, verbose=0, callbacks=[ f1metric ] )\n",
    "\n",
    "# load saved model\n",
    "loaded_model = load_model( modelpath + modelname + '.h5' )\n",
    "\n",
    "# get predictions (probabilities) for validation and test sets respectively\n",
    "yval = [ np.argmax(y, axis=None, out=None) for y in yval ]\n",
    "ytest = [ np.argmax(y, axis=None, out=None) for y in ytest ]\n",
    "valpredictions = loaded_model.predict( xval, verbose=0, batch_size=2048 )[ :, 1 ]\n",
    "testpredictions = loaded_model.predict( xtest, verbose=0, batch_size=2048 )[ :, 1 ]\n",
    "\n",
    "# optimizer threshold on validation set\n",
    "threshold = 0.5 #RUT_Utils.optimize_threshold( yval, valpredictions )\n",
    "\n",
    "# save accuracy, precision, recall, f1 and confusion matrices\n",
    "vallabels = (valpredictions>=threshold).astype( 'int32' )\n",
    "testlabels = (testpredictions>=threshold).astype( 'int32' )\n",
    "\n",
    "valaccuracy = accuracy_score( yval, vallabels )\n",
    "valprecision = precision_score( yval, vallabels )\n",
    "valrecall =  recall_score( yval, vallabels )\n",
    "valf1 =  f1_score( yval, vallabels )\n",
    "valcm =  confusion_matrix( yval, vallabels )    \n",
    "\n",
    "testaccuracy =  accuracy_score( ytest, testlabels )\n",
    "testprecision =  precision_score( ytest, testlabels )\n",
    "testrecall =  recall_score( ytest, testlabels )\n",
    "testf1 =  f1_score( ytest, testlabels )\n",
    "testcm =  confusion_matrix( ytest, testlabels )\n",
    "\n",
    "# save for future analysis and ensemble\n",
    "# com_indices.extend( test_index.tolist() )\n",
    "# com_text.extend( df.loc[ test_index ][ 'Comment' ] )\n",
    "# com_label.extend( df.loc[ test_index ][ 'Toxic' ].tolist() )\n",
    "# com_predicted.extend( testlabels[:,0].tolist() )\n",
    "# com_prob.extend( testpredictions[:,0].tolist() )\n",
    "\n",
    "# print( 'Fold: {:02d} out of {:02d} completed.'.format( fold, skf.get_n_splits() ) )\n",
    "\n",
    "# fold = fold + 1\n",
    "time_took = time.time() - start_time\n",
    "print(f\"Total runtime: {hms_string(time_took)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:0.9437042842215256\n",
      "\n",
      "Validation Precision0.7512116316639742\n",
      "\n",
      "Validation Recall0.6266846361185984\n",
      "\n",
      "Validation F10.683321087435709\n"
     ]
    }
   ],
   "source": [
    "print( 'Validation Accuracy:' + str(valaccuracy) + '\\n' )\n",
    "\n",
    "print( 'Validation Precision: ' + str(valprecision) + '\\n' )\n",
    "\n",
    "print( 'Validation Recall: ' + str(valrecall) + '\\n' )\n",
    "\n",
    "print( 'Validation F1: ' + str(valf1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 465  277]\n",
      " [ 154 6760]]\n",
      "\n",
      "\n",
      "TN :6760\n",
      "FP :154\n",
      "FN :277\n",
      "TP :465\n"
     ]
    }
   ],
   "source": [
    "print( np.rot90(np.rot90(valcm)) )\n",
    "\n",
    "_tn, _fp, _fn, _tp = valcm.ravel()\n",
    "print ( '\\n\\nTN :' +  str(_tn) )\n",
    "print ( 'FP :' +  str(_fp) )\n",
    "print ( 'FN :' +  str(_fn) )\n",
    "print ( 'TP :' +  str(_tp) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9439364648100736\n",
      "\n",
      "Test Precision: 0.7416173570019724\n",
      "\n",
      "Test Recall: 0.6238938053097345\n",
      "\n",
      "Test F1: 0.6776809852808651\n"
     ]
    }
   ],
   "source": [
    "print( 'Test Accuracy: ' +  str(testaccuracy) + '\\n' )\n",
    "\n",
    "print( 'Test Precision: ' +  str(testprecision) + '\\n' )\n",
    "\n",
    "print( 'Test Recall: ' +  str(testrecall) + '\\n' )\n",
    "\n",
    "print( 'Test F1: ' + str(testf1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1128   680]\n",
      " [  393 16938]]\n",
      "\n",
      "\n",
      "TN :16938\n",
      "FP :393\n",
      "FN :680\n",
      "TP :1128\n"
     ]
    }
   ],
   "source": [
    "print( np.rot90(np.rot90(testcm)) )\n",
    "\n",
    "_tn, _fp, _fn, _tp = testcm.ravel()\n",
    "print ( '\\n\\nTN :' +  str(_tn) )\n",
    "print ( 'FP :' +  str(_fp) )\n",
    "print ( 'FN :' +  str(_fn) )\n",
    "print ( 'TP :' +  str(_tp) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6652343137767097\n",
      "\n",
      "Test Precision: 0.6083226303621886\n",
      "\n",
      "Test Recall: 0.9279295752573011\n",
      "\n",
      "Test F1: 0.7348800645448246\n",
      "[[35523  2759]\n",
      " [22872 15410]]\n",
      "\n",
      "\n",
      "TN :15410\n",
      "FP :22872\n",
      "FN :2759\n",
      "TP :35523\n"
     ]
    }
   ],
   "source": [
    "synthetic = pd.read_csv('Synthetic_debias_test.csv')\n",
    "\n",
    "synthetic_comments = tokenizer.texts_to_sequences( synthetic['Comment'].values )\n",
    "\n",
    "# pad the tokenized sequences\n",
    "synthetic_comments_ = sequence.pad_sequences( synthetic_comments, maxlen=max_len )\n",
    "\n",
    "synthetic_y = synthetic['Toxic'].values\n",
    "synthetic_y = to_categorical( synthetic_y, 2 )\n",
    "\n",
    "synthetic_y = [ np.argmax(y, axis=None, out=None) for y in synthetic_y ]\n",
    "synthetic_predictions = loaded_model.predict( synthetic_comments_, verbose=0, batch_size=2048 )[ :, 1 ]\n",
    "\n",
    "synthetic_labels = (synthetic_predictions>=threshold).astype( 'int32' )\n",
    "synthetic_accuracy =  accuracy_score( synthetic_y, synthetic_labels )\n",
    "synthetic_precision =  precision_score( synthetic_y, synthetic_labels )\n",
    "synthetic_recall =  recall_score( synthetic_y, synthetic_labels )\n",
    "synthetic_f1 =  f1_score( synthetic_y, synthetic_labels )\n",
    "synthetic_cm =  confusion_matrix( synthetic_y, synthetic_labels )\n",
    "\n",
    "print( 'Test Accuracy: ' +  str(synthetic_accuracy) + '\\n' )\n",
    "\n",
    "print( 'Test Precision: ' +  str(synthetic_precision) + '\\n' )\n",
    "\n",
    "print( 'Test Recall: ' +  str(synthetic_recall) + '\\n' )\n",
    "\n",
    "print( 'Test F1: ' + str(synthetic_f1) )\n",
    "\n",
    "print( np.rot90(np.rot90(synthetic_cm)) )\n",
    "\n",
    "_tn, _fp, _fn, _tp = synthetic_cm.ravel()\n",
    "print ( '\\n\\nTN :' +  str(_tn) )\n",
    "print ( 'FP :' +  str(_fp) )\n",
    "print ( 'FN :' +  str(_fn) )\n",
    "print ( 'TP :' +  str(_tp) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic.drop(columns='PredictedLabel', inplace=True)\n",
    "synthetic['Predicted_Probability'] = synthetic_predictions\n",
    "synthetic['Predicted_Label'] = synthetic_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Toxic</th>\n",
       "      <th>Jew</th>\n",
       "      <th>Muslim</th>\n",
       "      <th>Christian</th>\n",
       "      <th>Hindu</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Black</th>\n",
       "      <th>White</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>Heterosexual</th>\n",
       "      <th>Homosexual_gay_or_lesbian</th>\n",
       "      <th>Sum</th>\n",
       "      <th>Predicted_Probability</th>\n",
       "      <th>Predicted_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>murder american</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022528</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>respect trans</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008496</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>respect homosexual</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008496</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hug mexican</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.282306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kill sikh</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.797720</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Comment  Toxic  Jew  Muslim  Christian  Hindu  Asian  Black  \\\n",
       "0     murder american      1    0       0          0      0      0      0   \n",
       "1       respect trans      0    0       0          0      0      0      0   \n",
       "2  respect homosexual      0    0       0          0      0      0      0   \n",
       "3         hug mexican      0    0       0          0      0      0      0   \n",
       "4           kill sikh      1    0       0          0      0      0      0   \n",
       "\n",
       "   White  Female  Male  Heterosexual  Homosexual_gay_or_lesbian  Sum  \\\n",
       "0      0       0     0             0                          0    0   \n",
       "1      0       0     0             0                          0    0   \n",
       "2      0       0     0             0                          1    1   \n",
       "3      0       0     0             0                          0    0   \n",
       "4      0       0     0             0                          0    0   \n",
       "\n",
       "   Predicted_Probability  Predicted_Label  \n",
       "0               0.022528                0  \n",
       "1               0.008496                0  \n",
       "2               0.008496                0  \n",
       "3               0.282306                0  \n",
       "4               0.797720                1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic.to_csv('./Results/'+modelname+'_synthetic_predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
